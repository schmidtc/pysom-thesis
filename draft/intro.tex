\chapter{INTRODUCTION}
The Self-Organizing Map (SOM) is an unsupervised competitive learning process
developed by Teuvo Kohonen as a technique to analyze and visualize high
dimensional data sets.  The applications of SOM are far reaching;
\cite{Kohonen2000} provides a thorough review of the SOM literature including
applications of SOM.  SOM has been used in applications ranging from speech
recognition and image classification to breast cancer detection and gene
expression clustering.  \cite{skupin08} outline the growing interest in SOM
within GIScience, and propose that the relationship between SOM and GIScience
should be bidirectional.  The SOM offers a powerful method for exploring and
visualizing geographic data and GIScience offers a wide array of tools
and methods to enable the exploration of the SOM itself.  The exploration of
spatial relationships has always been of great interest to geographers, and as
\cite{ritter99} states, the goal of SOM is ``to translate \emph{data
similarities} into \emph{spatial relationships}'' \citep[p. 1]{ritter99}.  This thesis leverages
GeoVisualization and GeoComputation in order to explore some of the basic
properties of the SOM.

The SOM is a type of artificial neural network in which neurons are ``organized''
in such a way as to project the high-dimensional relationships of a set of
training data onto a low-dimensional network structure.  The traditional
SOM uses a rectangular or hexagonal network topology \citep{Kohonen2000}.  These topologies 
create a well-known problem in SOM called the boundary or edge effect.  Neurons on
the boundary of the hexagonal and rectangular lattices have fewer neighbors,
which reduces their ability to interact with other neurons during the
self-organizing process.  Using a spherical lattice has been widely suggested as a
solution to the problem \citep{ritter99, boudjemai2003, sangole03,
Nishio:2006fk, wu2006}. The use of the spherical lattice, however, does not
completely overcome the problems caused by topology, and the choice of which spherical
topology to use for the network can be difficult to make.

A regular network topology is one in which every node on the network has exactly the
same number of adjacent nodes.  Any topology involving an edge is irregular.
Arranging our lattice on the surface of a sphere seems to be an obvious
way to overcome the edge.  However, there exist only five arrangements on the
sphere which are completely regular; these are the five platonic solids \citep{ritter99,
harris2000}.  Any other arrangement of neurons on the surface of the sphere will
result in an irregular topology, as not all neurons will have the same number of
neighbors.  The classic method for minimizing this irregularity is to generate
the spherical lattice by tessellating (subdividing) the sides of the icosahedron
\citep{Nishio:2006fk}.  While this method will always result in a highly
regular spherical topology, the main drawback is that the number of neurons in
the network (the network size), \(N\), grows exponentially as tessellations are
applied. That results in only very coarse control over network size.
 Other methods for arranging neurons on the sphere allow
for unlimited control over network size, but yield topologies with increased
irregularity \citep{harris2000, wu2005, Nishio:2006fk}.  To date the
literature has largely ignored the more irregular methods in favor of the
aforementioned tessellation-based methods.  A topology which yields a more flexible network
size may be desirable.  However, in order to address this issue of network
size, we must first determine the degree to which irregularity effects the
SOM.

\section{Research Objectives}
The objective of this research is to determine the utility of certain irregular
spherical topologies beyond offering greater control over network size.  Toward
that end, we develop and test new diagnostics to measure and visualize
topology-induced errors in SOM.  The following diagnostics are developed and
implemented:

\begin{enumerate}
    	\item Compare the internal heterogeneity of observations captured by a given neuron to that neuron's first-order neighborhood size.
	\item For different topologies, compare the internal heterogeneity of each neuron against a composite measure of topological regularity.
	\item Develop a SOM-based visualization of the internal heterogeneity.
	%\item Develop a reverse quantization error visualization by mapping neurons back onto the input data.
\end{enumerate}

These diagnostics help facilitate the evaluation of both traditional and
spherical SOMs.  To satisfy the objective of this research, we apply these
diagnostics to a series of comparable SOMs.  Each SOM is trained using the
same synthetic data and training parameters, but utilize different network
topologies.  By formally testing for difference of means and variance in the
results of the diagnostics, the following questions are addressed:

%topologies.  By formally testing for statistical differences in the
%results of the diagnostics the following questions will be addressed:
\begin{enumerate}
	\item Does the internal heterogeneity of a neuron decrease as its first-order neighborhood size, or degree, increases?
	\item Is the average internal heterogeneity of a SOM higher when a more irregular topology is used?
	\item Which insights, if any, can be gained from a SOM-based visualization of internal heterogeneity?
\end{enumerate}

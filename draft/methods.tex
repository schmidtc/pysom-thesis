\chapter{METHODOLOGY}
This chapter is composed of two sections.  The first describes the diagnostics
developed for evaluating network topologies.  The second describes an
empirical study that will implement these methods in order to evaluate the
utility of topologies that allow for greater control over network size.


\section{Diagnostics}
Three diagnostics are developed to explore the effect of irregular topology on
spherical SOM.  All three build on the idea of an internal variance \(IV\). The
internal variance of neuron (\(i\)) is defined as,
 \begin{equation}
   {IV_i} = \frac{2}{{n_i}^2-{n_i}}\sum_{j=1}^{n_i}\sum_{k=j}^{n_i} ||{x_{ij}}-{x_{ik}}||
 \label{eqno1}
 \end{equation}
where, \(n_i\) is the number of observations mapped to \(i\), and \(x_i\) are
the input vectors mapped to \(i\).

The first diagnostic will be used to address the research question regarding
the internal variance and neighborhood size.  The second diagnostic will
address the question concerning internal variance and topological
irregularity.  The third tool will help visualize the patterns between
internal variance and topology.

\subsection{Internal variance vs. first-order neighborhood size}
\label{q1}
This diagnostic will compare the internal variance of each neuron against its
first-order neighborhood size.  In traditional SOMs, outlying observations are
pushed to the edge of the map where they encounter fewer competing signals. A
prime example of this is the ``Utah-Hawaii'' case shown in Figure
\ref{figure1}.  Relying only on the SOM, one would be left to believe that the
two states are similar. Upon closer inspection we see that the QError from
Utah to the neuron is $1.509$, the QError from Hawaii to the neuron in
$1.505$, but the QError from Utah to Hawaii is $3.014$. In this case only Utah
and Hawaii were mapped to that neuron.  In a case where multiple observations
land on the same neuron, it is possible to measure average pairwise QErrors
between those observations.  This gives us a notion of internal variance for
each neuron. It would be expected that in traditional SOMs neurons closer to
the edge will have higher internal variances. This can be extended to
spherical SOMs by comparing the degree of a neuron ($deg(m_i)$ or the number of
adjacent neurons) to its internal variance.  The degree of each neuron can
easily be calculated by taking the column sums of the first-order adjacency
matrix ($A$).

Once the internal variance ($var(m_i)$) and degree ($deg(m_i)$) of each neuron
have been calculated, the neurons can be separated into a small number of
groups based on the degree \footnote{For most topologies the number of
different degrees will be limited to three or four.}.  The variance and mean
will be calculated for each of these groups.  The expected result is that
variances and means of the groups will decrease as the degree increases.  This
hypothesis will be tested using random labeling as described by \cite{siss2004}.
The result will also be visualized using a box plot.

\subsection{Internal variance vs. topological regularity}
This diagnostic will compare the internal variance of each neuron against a
measure of regularity for its associated topology.  As mentioned above the
degree of each neuron can be calculated by taking the column sums of $A$.  A
completely regular network topology (i.e. the torus) will have no variance
between these column sums.  For irregular networks the variance between these
column sums gives us a measure of irregularity. There are many alternative
ways to classify the connectivity of a network; \cite{florax95} outline four
such summary measures, which will be evaluated for use in this diagnostic.
For each topology we can compare the internal variances as described above
against a measure that summarizes the given topology's regularity.

This diagnostic is evaluated in much the same way as the last diagnostic.  
The internal variances are this time grouped by their topology.  We can then
compare the variances of internal variances and the means of the internal
variances across topologies.  It is expected that the distribution of internal
variances will be narrower for groups trained on more regular topologies.
It is further hypothesized that the means of these internal variances will
decrease when the network is more regular, or when there is less variance in
the column sums of $A$.  
%These assumptions will be tested using a \emph{t-test} on the means and an \emph{F-test} on the variances.

\subsection{Visualize internal variance mapping}
Visualizing the internal variance may yield insight into how irregular topology
effects the SOM.  Once the internal variance of each neuron has been calculated
we can use the values to color or shade a map of the given topology.  The degree
of the neurons can be visualized using proportional symbols to help show
patterns between internal variance and irregularity.

\section{Empirical Analysis}
The empirical analysis consists of three main tasks.  The first is to create
synthetic data suitable for the diagnostics described above.  The second task is
to train multiple SOMs, each with a different topology. The third task
is to apply the diagnostics and interpret the results.

\subsection{Synthetic Data}
%Comment from Skupin...
%This section is obviously leaving most of the specifics of the synthetic data
%generation out, which is problematic. I'm willing to go along with this for
%the proposal though, unless it gets raised by the third committee member
The internal variance measure is sensitive to both the properties of the SOM
and the properties of the training data. Therefore, a dataset with uniform
properties is needed. We follow the method for generating uniform synthetic
data used by \cite{wu2006}.  The dataset consists of seven clusters in three
dimensions.  Each cluster is normally distributed and has a standard deviation
of one.  The uniform clusters generated by this method allow us to
systematically compare the diagnostics under several different topologies.  To
ensure that we can calculate an internal variance for each neuron, we create a
large number of observations relative to the number of neurons.


%We will create a number of different data sets and use them to train various SOMs.  

%the data is generated in such a way to increase the probability that each neuron will be occupied by more than one observation.

%Initially the synthetic data for this thesis came from a Gaussian cluster
%generator which creates clusters by randomly sampling from multivariate
%normal distributions \citep{handl}.  \citeauthor{handl}' method to keep
%clusters from overlapping is to create one cluster at a time, with each new
%cluster checked to see if it overlaps with an existing cluster. If it does,
%it is rejected.  The generator continues until the desired number of
%non-overlapping clusters has been reached.  This method tends to create
%clusters of very different shapes and sizes (or extents).

%The limit to using this method for creating data became evident when we
%realized that the internal variance measure was being affected by the
%structure of the clusters.  The internal variance essentially looks at the
%portion of a cluster that is mapped to a particular neuron and measures the
%density.  Because we specify that each cluster contain an equal number of
%observations, they tend to get equal representation (in terms of number of
%neurons) on the trained SOM.  The result of all this is that the smaller,
%more dense clusters display very low internal variance relative to the
%larger, less dense clusters.  While this may have interesting consequences in
%other applications, because of these effects on the internal variance our
%ability to determine how changes in the topology are affecting the meassure.
%because it interferes with the measurement of internal variance, we had to
%adopt another method of synthetic data generation. 



\subsection{Training}
Before we can go on to address the research questions we need to train a
series of SOMs.  We will train SOMs using four different topologies:
\emph{rectangular, hexagonal, geodesic sphere and spherical}.  The spherical
topology is based on a method, developed by \cite{Rakhmanov94}, for
distributing an arbitrary number of points on to the surface of a sphere.
Delaunay triangulation is then applied to these points, producing a
topological structure.  To yield meaningful results those SOMs must be trained
with comparable parameters.  The literature provides many rules of thumb for training a SOM.
Each SOM is trained in two stages.  The first stage uses a larger
initial learning rate and neighborhood search radius with a small number of
training steps.  In the second stage we lower the initial learning rate and
the neighborhood search radius, but extend the length of training.
\\
First Stage Parameters:
\begin{itemize}
  \item Initial neighborhood search radius of 50\%, which decreases during training. 
  \item The initial learning rates of 0.04 which decreases during training.
  \item 100,000 training steps.
\end{itemize}
Second Stage Parameters:
\begin{itemize}
  \item Initial neighborhood search radius of 33\%, which decreases during training. 
  \item The initial learning rates of 0.03 which decreases during training.
  \item 1,000,000 training steps.
\end{itemize}

As shown in Figure \ref{fig:nSize}, topologies differ in terms of achievable
network size.  For comparability, the network size of each SOM needs to be as
close as possible.  The achievable network size for the geodesic SOM is the
most limiting of the topologies we test. We chose the eighth frequency
geodesic sphere, which has 642 nodes, which is relatively close to the
644-node hexagonal and rectangular topologies achieved when the dimensions are
set to \(28x23\). Finally, the spherical topology was set to 642 nodes.

One problem that we face is a small sample size when the neurons of a given
SOM are grouped by their degree.  For example, the four corners of the
rectangular topology are the only neurons that have a degree of two.  The rest
of the neurons have three or four neighbors depending on whether or not they
are on the edge. To address the problem of small sample size for topologies
with relatively few neurons of a particular degree, we will increase
the sample size by combining the results of many SOMs.

Ten synthetic datasets are generated using the parameters described above.
The datasets are used to train SOMs for each topology resulting in forty
trained SOMs. The mean internal variance of these SOMs is summarized in Table
\ref{ivtable3}.  We find that the mean internal variance remains fairly
stable, suggesting that the results of each simulation can be combined within
a given topology.  For the rectangular topology, we now have forty neurons
with a degree of two for which an internal variance can be
calculated.\footnote{We can only measure the internal variance when a neuron
captures two or more observations from the training data.  Therefore, it is
still possible to have less than forty measurements.}

\begin{table}[hbt]
\centering
\caption{Mean internal variance for each simulation, by topology.}
\label{ivtable3}
\begin{tabular}{|c||c|c|c|c|}
\hline
\textbf{Simulation} & Geodesic & Graph & Hex & Rook \\
\hline
\hline
\textbf{1} & 0.0277 & 0.0277 & 0.0285 & 0.0289 \\
\textbf{2} & 0.0281 & 0.0281 & 0.0291 & 0.0295 \\
\textbf{3} & 0.0278 & 0.0280 & 0.0286 & 0.0292 \\
\textbf{4} & 0.0280 & 0.0282 & 0.0286 & 0.0293 \\
\textbf{5} & 0.0279 & 0.0280 & 0.0289 & 0.0296 \\
\textbf{6} & 0.0278 & 0.0274 & 0.0285 & 0.0290 \\
\textbf{7} & 0.0286 & 0.0283 & 0.0294 & 0.0297 \\
\textbf{8} & 0.0284 & 0.0285 & 0.0294 & 0.0298 \\
\textbf{9} & 0.0283 & 0.0282 & 0.0293 & 0.0295 \\
\textbf{10}& 0.0285 & 0.0285 & 0.0293 & 0.0298 \\
\hline
\hline
\textbf{Combined} & 0.0281 & 0.0281 & 0.0290 & 0.0294\\
\hline
\end{tabular} \end{table}



\subsection{Diagnostics}
The first diagnostic will yield a set of results for each topology tested.  These
results will be analyzed in order to address the first research question of this
paper.  The second diagnostic provides one set of results.  These results will
be analyzed to address the second research question.  The final diagnostic will
return a visualization for each topology tested.  The usefulness of these
visualizations is a research question in itself.  The expectation is that the
visualizations will show patterns of internal variance related to irregularities
in the network topology.

